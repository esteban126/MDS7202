{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ac9155b9f5e04400957a6f8bb3f6610c",
    "deepnote_cell_type": "markdown",
    "id": "2v2D1coL7I8i"
   },
   "source": [
    "<h1><center>Laboratorio 4: La solicitud de Sergio ü§ó</center></h1>\n",
    "\n",
    "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos - Oto√±o 2025</strong></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d3d6f6d405c54dbe985a5f4b3e4f9120",
    "deepnote_cell_type": "markdown",
    "id": "YxdTmIPD7L_x"
   },
   "source": [
    "### Cuerpo Docente:\n",
    "\n",
    "- Profesores: Stefano Schiappacasse, Sebasti√°n Tinoco\n",
    "- Auxiliares: Melanie Pe√±a, Valentina Rojas\n",
    "- Ayudantes: Angelo Mu√±oz, Valentina Z√∫√±iga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "851a7788e8214942863cbd4099064ab2",
    "deepnote_cell_type": "markdown",
    "id": "Y2Gyrj-x7N2L"
   },
   "source": [
    "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
    "\n",
    "- Esteban Rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f23a189afdec4e198683308db70e43b7",
    "deepnote_cell_type": "markdown",
    "id": "jQ9skYc57Pxi"
   },
   "source": [
    "### **Link de repositorio de GitHub:** https://github.com/esteban126/MDS7202"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b5318f41cda64d4290a7a548956ed725",
    "deepnote_cell_type": "markdown",
    "id": "1M4PoEWm7S80"
   },
   "source": [
    "## Temas a tratar\n",
    "- Aplicar Pandas para obtener caracter√≠sticas de un DataFrame.\n",
    "- Aplicar Pipelines y Column Transformers.\n",
    "- Utilizar diferentes algoritmos de cluster y ver el desempe√±o.\n",
    "\n",
    "## Reglas:\n",
    "\n",
    "- **Grupos de 2 personas**\n",
    "- Fecha de entrega: 6 d√≠as de plazo con descuento de 1 punto por d√≠a. Entregas Martes a las 23:59.\n",
    "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria, pero se recomienda fuertemente asistir.\n",
    "- <u>Prohibidas las copias</u>. Cualquier intento de copia ser√° debidamente penalizado con el reglamento de la escuela.\n",
    "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no est√©n en u-cursos no ser√°n revisados. Recuerden que el repositorio tambi√©n tiene nota.\n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
    "- Pueden usar cualquier material del curso que estimen conveniente.\n",
    "\n",
    "### Objetivos principales del laboratorio\n",
    "- Comprender c√≥mo aplicar pipelines de Scikit-Learn para generar clusters.\n",
    "- Familiarizarse con plotly.\n",
    "\n",
    "El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `numpy`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre arreglos (*o tensores*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "858df483d9e64780a21674afed1d34b8",
    "deepnote_cell_type": "markdown",
    "id": "SuMbiyQZG2Cc"
   },
   "source": [
    "## Descripci√≥n del laboratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "403ffe48ec994afda4b91e670a08d0ef",
    "deepnote_cell_type": "markdown",
    "id": "QZsNO4rUrqCz"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://i.pinimg.com/originals/5a/a6/af/5aa6afde8490da403a21601adf7a7240.gif\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0303baa17d4546feae8c9b88c58470bf",
    "deepnote_cell_type": "markdown",
    "id": "2o0MPuk8rqCz"
   },
   "source": [
    "En el coraz√≥n de las operaciones de Aerol√≠nea Lucero, Sergio, el gerente de an√°lisis de datos, reuni√≥ a un talentoso equipo de j√≥venes cient√≠ficos de datos para un desaf√≠o crucial: segmentar la base de datos de los clientes. ‚ÄúNuestro objetivo es descubrir patrones en el comportamiento de los pasajeros que nos permitan personalizar servicios y optimizar nuestras campa√±as de marketing,‚Äù explic√≥ Sergio, mientras desplegaba un amplio rango de datos que inclu√≠an desde h√°bitos de compra hasta opiniones sobre los vuelos.\n",
    "\n",
    "Sergio encarg√≥ a los cient√≠ficos de datos la tarea de aplicar t√©cnicas avanzadas de clustering para identificar distintos segmentos de clientes, como los viajeros frecuentes y aquellos que eligen la aerol√≠nea para celebrar ocasiones especiales. La meta principal era entender profundamente c√≥mo estos grupos perciben la calidad y satisfacci√≥n de los servicios ofrecidos por la aerol√≠nea.\n",
    "\n",
    "A trav√©s de un enfoque meticuloso y colaborativo, los cient√≠ficos de datos se abocaron a la tarea, buscando transformar los datos brutos en valiosos insights que permitir√≠an a Aerol√≠nea Lucero no solo mejorar su servicio, sino tambi√©n fortalecer las relaciones con sus clientes mediante una oferta m√°s personalizada y efectiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e78cb41b144041af98928ab26dcfdaa9",
    "deepnote_cell_type": "markdown",
    "id": "hs4KKWF1Hdpo"
   },
   "source": [
    "## Importamos librerias utiles üò∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "95a5533cfd6d49cfb9afc111c44d224f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 15,
    "execution_start": 1714107106552,
    "id": "a4YpMafirqC0",
    "scrolled": true,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "acbeab32db6146678e75448dddf43da8",
    "deepnote_cell_type": "markdown",
    "id": "UQOXod4gHhSq"
   },
   "source": [
    "## 1. Estudio de Performance üìà [10 Puntos]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "704b56b978254ad3ae12cdbf58f4832d",
    "deepnote_cell_type": "markdown",
    "id": "Gn5u5ICkrqC2"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://i.pinimg.com/originals/23/b7/6e/23b76e9e77e63c0eec1a7b28372369e3.gif\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d35fbdcc5ef045d6a2822622f0714179",
    "deepnote_cell_type": "markdown",
    "id": "y4Z0jTjtrqC2"
   },
   "source": [
    "Don Sergio les ha encomendado su primera tarea: analizar diversas t√©cnicas de clustering. Su objetivo es entender detalladamente c√≥mo funcionan estos m√©todos en t√©rminos de segmentaci√≥n y eficiencia en tiempo de ejecuci√≥n.\n",
    "\n",
    "Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering (k-means, DBSCAN, Ward y GMM) aplicados a tres conjuntos de datos, incrementando progresivamente su tama√±o. Utilice Plotly para las gr√°ficas y discuta los resultados tanto cualitativa como cuantitativamente.\n",
    "\n",
    "Uno de los requisitos establecidos por Sergio es que el an√°lisis se lleve a cabo utilizando Plotly; de no ser as√≠, se considerar√° incorrecto. Para facilitar este proceso, se ha proporcionado un c√≥digo de Plotly que puede servir como base para realizar las gr√°ficas. Ap√≥yese en el c√≥digo entregado para efectuar el an√°lisis y tome como referencia la siguiente imagen para realizar los gr√°ficos:\n",
    "\n",
    "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-04-26_at_9.10.44_AM.png' width=800 />\n",
    "\n",
    "En el gr√°fico se visualizan en dos dimensiones los diferentes tipos de datos proporcionados en `datasets`. Cada columna corresponde a un modelo de clustering diferente, mientras que cada fila representa un conjunto de datos distinto. Cada uno de los gr√°ficos incluye el tiempo en segundos que tarda el an√°lisis y la m√©trica Silhouette obtenida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "37580aab6cef4238a8ce42c50a6d35de",
    "deepnote_cell_type": "markdown",
    "id": "maCUNAvZrqC2"
   },
   "source": [
    "Para ser m√°s espec√≠ficos, usted debe cumplir los siguientes objetivos:\n",
    "1. Generar una funci√≥n que permita replicar el gr√°fico expuesto en la imagen (no importa que los colores calcen). [4 puntos]\n",
    "2. Ejecuta la funci√≥n para un `n_samples` igual a 1000, 5000, 10000. [2 puntos]\n",
    "3. Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering utilizando las 3 configuraciones dadas en `n_samples`. [4 puntos]\n",
    "\n",
    "\n",
    "> ‚ùó Tiene libertad absoluta de escoger los hiper par√°metros de los cluster, sin embargo, se recomienda verificar el dominio de las variables para realizar la segmentaci√≥n.\n",
    "\n",
    "> ‚ùó Recuerde que es obligatorio el uso de plotly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "7f7c25e366754595b13fc2e8116f65a0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 78,
    "execution_start": 1714107108441,
    "id": "i0IZPGPOrqC3",
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "En la siguiente celda se crean los datos ficticios a usar en la secci√≥n 1 del lab.\n",
    "‚ùóNo realice cambios a esta celda a excepci√≥n de n_samples‚ùó\n",
    "\"\"\"\n",
    "\n",
    "# Datos a utilizar\n",
    "\n",
    "# Configuracion\n",
    "n_samples = 5000 #Este par√°metro si lo pueden modificar\n",
    "\n",
    "def create_data(n_samples):\n",
    "\n",
    "    # Lunas\n",
    "    moons = datasets.make_moons(n_samples=n_samples, noise=0.05, random_state=30)\n",
    "    # Blobs\n",
    "    blobs = datasets.make_blobs(n_samples=n_samples, random_state=172)\n",
    "    # Datos desiguales\n",
    "    transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
    "    mutated = (np.dot(blobs[0], transformation), blobs[1])\n",
    "\n",
    "    # Generamos Dataset\n",
    "    dataset = {\n",
    "        'moons':{\n",
    "            'x': moons[0], 'classes': moons[1], 'n_cluster': 2\n",
    "        },\n",
    "        'blobs':{\n",
    "            'x': blobs[0], 'classes': blobs[1], 'n_cluster': 3\n",
    "        },\n",
    "        'mutated':{\n",
    "            'x': mutated[0], 'classes': mutated[1], 'n_cluster': 3\n",
    "        }\n",
    "    }\n",
    "    return dataset\n",
    "\n",
    "data_sets = create_data(n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y51s6f_UtIkc"
   },
   "source": [
    "**Respuestas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs, make_moons, make_circles\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering, SpectralClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import time\n",
    "\n",
    "def clustering_plotly_panel(n_samples=1000):\n",
    "    data_sets = create_data(n_samples)\n",
    "\n",
    "    clusterers = {\n",
    "        \"KMeans\": lambda n: KMeans(n_clusters=n, random_state=0),\n",
    "        \"DBSCAN\": lambda n: DBSCAN(eps=0.3, min_samples=5),\n",
    "        \"Agglomerative\": lambda n: AgglomerativeClustering(n_clusters=n),\n",
    "        \"Spectral\": lambda n: SpectralClustering(n_clusters=n, affinity='nearest_neighbors', assign_labels='kmeans', random_state=0)\n",
    "    }\n",
    "\n",
    "    dataset_names = list(data_sets.keys())\n",
    "    algo_names = list(clusterers.keys())\n",
    "\n",
    "    fig = make_subplots(rows=len(dataset_names), cols=len(algo_names),\n",
    "                        subplot_titles=[f\"{algo} - {name}\" for name in dataset_names for algo in algo_names])\n",
    "\n",
    "    for row_idx, name in enumerate(dataset_names, start=1):\n",
    "        data = data_sets[name]\n",
    "        X = StandardScaler().fit_transform(data['x'])\n",
    "        n_clusters = data['n_cluster']\n",
    "\n",
    "        for col_idx, algo_name in enumerate(algo_names, start=1):\n",
    "            algo_func = clusterers[algo_name]\n",
    "\n",
    "            try:\n",
    "                model = algo_func(n_clusters)\n",
    "                t0 = time.time()\n",
    "                y_pred = model.fit_predict(X)\n",
    "                elapsed = time.time() - t0\n",
    "            except Exception as e:\n",
    "                y_pred = np.zeros(X.shape[0])\n",
    "                elapsed = 0\n",
    "                print(f\"Error con {algo_name} en {name}: {e}\")\n",
    "\n",
    "            # Silhouette\n",
    "            try:\n",
    "                silhouette = silhouette_score(X, y_pred)\n",
    "            except:\n",
    "                silhouette = np.nan\n",
    "\n",
    "            # Scatter\n",
    "            scatter = go.Scatter(\n",
    "                x=X[:, 0], y=X[:, 1], mode='markers',\n",
    "                marker=dict(color=y_pred, colorscale='Viridis', size=3, showscale=False),\n",
    "                showlegend=False\n",
    "            )\n",
    "\n",
    "            fig.add_trace(scatter, row=row_idx, col=col_idx)\n",
    "\n",
    "            fig.add_annotation(\n",
    "                text=f\"S: {silhouette:.2f} T: {elapsed:.2f}s\",\n",
    "                xref=f\"x{(row_idx - 1) * len(algo_names) + col_idx}\",\n",
    "                yref=f\"y{(row_idx - 1) * len(algo_names) + col_idx}\",\n",
    "                x=0, y=2, showarrow=False, xanchor=\"center\", yanchor=\"bottom\",\n",
    "                row=row_idx, col=col_idx\n",
    "            )\n",
    "\n",
    "    fig.update_layout(height=1000, width=1200, title_text=f\"Comparaci√≥n de Clustering para n_samples={n_samples}\")\n",
    "    fig.show()\n",
    "\n",
    "for n in [1000, 5000, 10000]:\n",
    "    clustering_plotly_panel(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "643d6b35af5541358f481fda4d3fc51f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 267,
    "execution_start": 1714108733824,
    "id": "CO3JFqezrqC3",
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "def plot_scatter(x, y, color):\n",
    "    #Escriba su c√≥digo aqu√≠\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo que tiene el mejor desempe√±o es el KMeans para cada dataset y n√∫mero de samples, aunque vale notar que observando las visualizaciones parece ser mejor el Spectral; sin embargo el que tiene un menor tiempo de ejecuci√≥n est√° entre el KMeans y el DBSCAN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "13c5cb8067d9415f83b3d497954a437a",
    "deepnote_cell_type": "markdown",
    "id": "3mCbZc86rqC6"
   },
   "source": [
    "## 2. An√°lisis de Satisfacci√≥n de Vuelos. [10 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fd6e991646b44f50a4b13f01d1542415",
    "deepnote_cell_type": "markdown",
    "id": "JI33m5jbrqC6"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://i.gifer.com/2Hci.gif\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5742dfbd5a2e43778ff250436bab1005",
    "deepnote_cell_type": "markdown",
    "id": "h5k24znirqC7"
   },
   "source": [
    "Habiendo entendido c√≥mo funcionan los modelos de aprendizaje no supervisado, *Don Sergio* le encomienda estudiar la satisfacci√≥n de pasajeros al haber tomado un vuelo en alguna de sus aerolineas. Para esto, el magnate le dispone del dataset `aerolineas_licer.parquet`, el cual contiene el grado de satisfacci√≥n de los clientes frente a diferentes aspectos del vuelo. Las caracter√≠sticas del vuelo se definen a continuaci√≥n:\n",
    "\n",
    "- *Gender*: G√©nero de los pasajeros (Femenino, Masculino)\n",
    "- *Customer Type*: Tipo de cliente (Cliente habitual, cliente no habitual)\n",
    "- *Age*: Edad actual de los pasajeros\n",
    "- *Type of Travel*: Prop√≥sito del vuelo de los pasajeros (Viaje personal, Viaje de negocios)\n",
    "- *Class*: Clase de viaje en el avi√≥n de los pasajeros (Business, Eco, Eco Plus)\n",
    "- *Flight distance*: Distancia del vuelo de este viaje\n",
    "- *Inflight wifi service*: Nivel de satisfacci√≥n del servicio de wifi durante el vuelo (0:No Aplicable; 1-5)\n",
    "- *Departure/Arrival time convenient*: Nivel de satisfacci√≥n con la conveniencia del horario de salida/llegada\n",
    "- *Ease of Online booking*: Nivel de satisfacci√≥n con la facilidad de reserva en l√≠nea\n",
    "- *Gate location*: Nivel de satisfacci√≥n con la ubicaci√≥n de la puerta\n",
    "- *Food and drink*: Nivel de satisfacci√≥n con la comida y la bebida\n",
    "- *Online boarding*: Nivel de satisfacci√≥n con el embarque en l√≠nea\n",
    "- *Seat comfort*: Nivel de satisfacci√≥n con la comodidad del asiento\n",
    "- *Inflight entertainment*: Nivel de satisfacci√≥n con el entretenimiento durante el vuelo\n",
    "- *On-board service*: Nivel de satisfacci√≥n con el servicio a bordo\n",
    "- *Leg room service*: Nivel de satisfacci√≥n con el espacio para las piernas\n",
    "- *Baggage handling*: Nivel de satisfacci√≥n con el manejo del equipaje\n",
    "- *Check-in service*: Nivel de satisfacci√≥n con el servicio de check-in\n",
    "- *Inflight service*: Nivel de satisfacci√≥n con el servicio durante el vuelo\n",
    "- *Cleanliness*: Nivel de satisfacci√≥n con la limpieza\n",
    "- *Departure Delay in Minutes*: Minutos de retraso en la salida\n",
    "- *Arrival Delay in Minutes*: Minutos de retraso en la llegada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOoIFHpw5xCW"
   },
   "source": [
    "En consideraci√≥n de lo anterior, realice las siguientes tareas:\n",
    "\n",
    "0. Ingeste el dataset a su ambiente de trabajo.\n",
    "\n",
    "1. Seleccione **s√≥lo las variables num√©ricas del dataset**.  Explique qu√© √©fectos podr√≠a causar el uso de variables categ√≥ricas en un algoritmo no supervisado. [2 punto]\n",
    "\n",
    "2. Realice una visualizaci√≥n de la distribuci√≥n de cada variable y analice cada una de estas distribuciones. [2 punto]\n",
    "\n",
    "3. Bas√°ndose en los gr√°ficos, eval√∫e la necesidad de escalar los datos y explique el motivo de su decisi√≥n. [2 puntos]\n",
    "\n",
    "4. Examine la correlaci√≥n entre las variables mediante un correlograma. [2 puntos]\n",
    "\n",
    "5. De acuerdo con los resultados obtenidos en 5, reduzca la dimensionalidad del conjunto de datos a cuatro variables, justificando su elecci√≥n respecto a las variables que decide eliminar. [2 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tO6tcVBCtxxS"
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pzHTZ17xveU_"
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('aerolineas_lucer.parquet')\n",
    "\n",
    "# Variables num√©ricas\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "df_numeric = df[numeric_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efectos de variables categ√≥ricas en algoritmos no supervisados:\n",
    "\n",
    "* Problemas de interpretaci√≥n: Los algoritmos no supervisados como K-means o PCA generalmente trabajan con distancias (euclidianas, coseno, etc.), y las categor√≠as no tienen un orden intr√≠nseco que permita calcular estas distancias de manera significativa.\n",
    "\n",
    "* Necesidad de transformaci√≥n: Para usar variables categ√≥ricas, se deben aplicar t√©cnicas como one-hot encoding, lo que puede:\n",
    "\n",
    "    * Aumentar significativamente la dimensionalidad (problema de \"curse of dimensionality\")\n",
    "\n",
    "    * Crear dispersi√≥n en los datos ya que cada categor√≠a se convierte en una variable binaria\n",
    "\n",
    "    * Hacer que algunas categor√≠as dominen artificialmente la distancia debido a la alta dimensionalidad\n",
    "\n",
    "* Resultados sesgados: La inclusi√≥n directa de variables categ√≥ricas sin tratamiento adecuado puede llevar a agrupamientos que reflejen m√°s las codificaciones arbitrarias que patrones reales en los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Configuraci√≥n de los gr√°ficos\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Crear figura con subplots\n",
    "fig = make_subplots(rows=5, cols=5, subplot_titles=df_numeric.columns)\n",
    "\n",
    "# A√±adir histogramas para cada variable\n",
    "for i, col in enumerate(df_numeric.columns, 1):\n",
    "    row = (i-1)//5 + 1\n",
    "    col_pos = (i-1)%5 + 1\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=df_numeric[col], name=col),\n",
    "        row=row, col=col_pos\n",
    "    )\n",
    "\n",
    "# Actualizar dise√±o\n",
    "fig.update_layout(\n",
    "    title_text=\"Distribuci√≥n de Variables Num√©ricas\",\n",
    "    height=800,\n",
    "    width=1500,\n",
    "    showlegend=False\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Age: La edad tiene una distribuci√≥n normal con mediana en los 40.\n",
    "* Flight Distance: Tiene una tendencia hacia los vuelos de menos distancia por el orden de los 300 kms.\n",
    "* Inflight wifi service: El servicio de Wifi tiene un nivel de satifacci√≥n con una distribuci√≥n normal entre los 2 y 3.\n",
    "* Departure/Arrival time convenient: Hay un alto nivel de satisfacci√≥n, donde la mayor√≠a est√° entre 4 y 5.\n",
    "* Ease of Online booking: Tiene una distribuci√≥n normal con media entre los 2 y 3.\n",
    "* Gate location: La ubicaci√≥n de la puerta tiene un nivel de satifacci√≥n con una distribuci√≥n normal con la media sobre los 3.\n",
    "* Food and drink: Tiene una tendencia hacia buenas calificaciones la comida y la bebida.\n",
    "* Online boarding: Tiene una distribuci√≥n normal con tendencia a la derecha, con la media en el 4.\n",
    "* Seat comfort: La distribuci√≥n es similar a la feature anterior.\n",
    "* Inflight entertainment: La distribuci√≥n es similar a la feature anterior.\n",
    "* On-board service: La distribuci√≥n es similar a la feature anterior.\n",
    "* Leg room service: La distribuci√≥n es similar a la feature anterior.\n",
    "* Baggage handling: La distribuci√≥n es similar a la feature anterior.\n",
    "* Checkin service: La distribuci√≥n es similar a la feature anterior.\n",
    "* Inflight service: La distribuci√≥n es similar a la feature anterior.\n",
    "* Cleanliness: La distribuci√≥n es similar a la feature anterior.\n",
    "* Departure Delay in Minutes: Tiene poco retraso de la partida del vuelo.\n",
    "* Arrival Delay in Minutes: Tiene poco retraso de la llegada del vuelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es necesario escalar las features, dado que hay variables con escalas muy dispares (del 0‚Äì5 vs. miles). Esto distorsiona las distancias y hace que, por ejemplo, Flight Distance tenga mucho m√°s peso que Seat comfort en el clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_numeric.drop(columns=['id']).corr()\n",
    "\n",
    "# Correlograma con plotly\n",
    "fig = px.imshow(corr,\n",
    "                labels=dict(color=\"Correlaci√≥n\"),\n",
    "                x=corr.columns,\n",
    "                y=corr.columns,\n",
    "                color_continuous_scale='RdBu',\n",
    "                zmin=-1, zmax=1,\n",
    "                title=\"Correlograma de variables num√©ricas\")\n",
    "\n",
    "fig.update_layout(width=900, height=900)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An√°lisis del correlograma:\n",
    "\n",
    "Inflight wifi service, Inflight entertainment, Online boarding, Seat comfort, On-board service, etc., tienen correlaci√≥n alta entre s√≠ (por encima de 0.7), lo cual indica redundancia.\n",
    "\n",
    "Flight Distance, Departure Delay, Arrival Delay tienen baja correlaci√≥n con las anteriores, por lo que aportan informaci√≥n distinta.\n",
    "\n",
    "Algunas variables como Gate location o Ease of Online booking tiene baja correlaci√≥n con casi todas, lo que las hace poco √∫tiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto las variables que se quedar√≠an son:\n",
    "\n",
    "* Flight Distance:\tTiene alta varianza y es poco redundante\n",
    "* Inflight entertainment:\tRepresenta bien el bloque de experiencia abordo\n",
    "* Online boarding:\tRepresenta el bloque de servicios digitales\n",
    "* Departure Delay in Minutes:\tRepresenta la dimensi√≥n de puntualidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4b6c047d994f40ea9e78a36a777042e0",
    "deepnote_cell_type": "markdown",
    "id": "PNGfTgtkrqC9"
   },
   "source": [
    "## 3. Preprocesamiento üé≠. [10 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "713b3f0e61dd4841bb5b38c730d344d5",
    "deepnote_cell_type": "markdown",
    "id": "6RZD0fMNrqC-"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://media4.giphy.com/media/vWst8QUOKAot6MHEZe/giphy.gif?cid=6c09b952gm5xylrj4k5caq2slgwivx9azbgb0ox297sk5zjx&ep=v1_internal_gif_by_id&rid=giphy.gif&ct=g\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "98400c7b5fec4af193eec3601f53891e",
    "deepnote_cell_type": "markdown",
    "id": "J6d4VEOTrqC-"
   },
   "source": [
    "Tras quedar satisfecho con los resultados presentados en el punto 2, el due√±o de la empresa ha solicitado que se preprocesen los datos mediante un `pipeline`. Es crucial que este proceso tenga en cuenta las observaciones derivadas de los an√°lisis anteriores. Adicionalmente, ha expresado su inter√©s en visualizar el conjunto de datos en un gr√°fico de dos o tres dimensiones.\n",
    "\n",
    "Bas√°ndose en los an√°lisis realizados anteriormente:\n",
    "1. Cree un `pipeline` que incluya PCA, utilizando las consideraciones mencionadas previamente para proyectar los datos a dos dimensiones. [4 puntos]\n",
    "2. Grafique los resultados obtenidos y comente lo visualizado. [6 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paDSaGoq0OUp"
   },
   "source": [
    "**Respuestas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ad1e70818ad748638ca0927b07a76125",
    "deepnote_cell_type": "code",
    "id": "gBYG238wrqC-"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "selected_cols = ['Flight Distance', 'Inflight entertainment', 'Ease of Online booking', 'Departure Delay in Minutes']\n",
    "\n",
    "# 2. Preparamos el ColumnTransformer (escalado)\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('scaler', StandardScaler(), selected_cols)\n",
    "])\n",
    "\n",
    "# 3. Pipeline con PCA\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('pca', PCA(n_components=2))\n",
    "])\n",
    "\n",
    "# 4. Ajustamos el pipeline y transformamos\n",
    "pca_result = pipeline.fit_transform(df[selected_cols])\n",
    "pca_df = pd.DataFrame(pca_result, columns=['PC1', 'PC2'])\n",
    "\n",
    "fig = px.scatter(\n",
    "    pca_df,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    title='Proyecci√≥n PCA en 2D',\n",
    "    opacity=0.6\n",
    "    # color=df['Satisfaction']  # Descomenta si tienes una variable categ√≥rica\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=3))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bd281470d3054764a63d857cfa7d52a6",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [],
    "id": "7ENoOtIIrqC_"
   },
   "source": [
    "## 4. Outliers üö´üôÖ‚Äç‚ôÄÔ∏è‚ùåüôÖ‚Äç‚ôÇÔ∏è [10 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "db89e9c9f35c44abbd8991180226c0ea",
    "deepnote_cell_type": "markdown",
    "id": "fbGw6Sa-rqC_"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://joachim-gassen.github.io/images/ani_sim_bad_leverage.gif\" width=250>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3e2f59fa12954641af7a854a4e203694",
    "deepnote_cell_type": "markdown",
    "id": "nl_ccu9brqDA"
   },
   "source": [
    "Con el objetivo de mantener la claridad en su an√°lisis, Don Sergio le ha solicitado entrenar un modelo que identifique pasajeros con comportamientos altamente at√≠picos.\n",
    "\n",
    "1. Utilice `IsolationForest` para clasificar las anomal√≠as del dataset (sin aplicar PCA), configurando el modelo para que s√≥lo el 1% de los datos sean considerados an√≥malos. Aseg√∫rese de integrar esta tarea dentro de un `pipeline`. [3 puntos]\n",
    "\n",
    "2. Visualice los resultados en el gr√°fico de dos dimensiones previamente creado. [3 puntos]\n",
    "\n",
    "3. ¬øC√≥mo evaluar√≠a el rendimiento de su modelo en la detecci√≥n de anomal√≠as? [4 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5cS1FR00NlF"
   },
   "source": [
    "**Respuestas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "be86896911244aa89e3b5f3f00a286af",
    "deepnote_cell_type": "code",
    "id": "iaPZFmjyrqDA"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Preprocesamiento (escalado)\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('scaler', StandardScaler(), selected_cols)\n",
    "])\n",
    "\n",
    "# Modelo IsolationForest\n",
    "iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
    "\n",
    "# Pipeline\n",
    "anomaly_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('isolation_forest', iso_forest)\n",
    "])\n",
    "\n",
    "# Entrenar modelo\n",
    "anomaly_pipeline.fit(df[selected_cols])\n",
    "\n",
    "# Predicci√≥n de anomal√≠as (-1 = outlier, 1 = normal)\n",
    "df['anomaly'] = anomaly_pipeline.predict(df[selected_cols])\n",
    "df.anomaly.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df['anomaly'] = df['anomaly'].map({1: 'Normal', -1: 'An√≥malo'}).reset_index().anomaly\n",
    "\n",
    "fig = px.scatter(\n",
    "    pca_df,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    color='anomaly',\n",
    "    title='Visualizaci√≥n de Anomal√≠as detectadas con Isolation Forest (1%)',\n",
    "    opacity=0.6,\n",
    "    color_discrete_map={'Normal': 'blue', 'An√≥malo': 'red'}\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=4))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo Isolation Forest ha sido entrenado correctamente para identificar pasajeros con comportamientos at√≠picos. El 1% de los datos fue marcado como an√≥malo, y al proyectarlos en dos dimensiones con PCA, se visualiza que estos casos se distribuyen fuera de las zonas m√°s densas del gr√°fico, lo que respalda la validez del modelo.\n",
    "\n",
    "Aunque no contamos con etiquetas reales para confirmar estas anomal√≠as, los resultados son coherentes con las expectativas para este tipo de modelo no supervisado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3871e2fe5bdd422dbdbfaebf75503ae3",
    "deepnote_cell_type": "markdown",
    "id": "zQFTklmVrqDB"
   },
   "source": [
    "## 5. M√©tricas de Desempe√±o üöÄ [10 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "236333de6dd445c182aefcc507589325",
    "deepnote_cell_type": "markdown",
    "id": "YpNj4wbPrqDB"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://giffiles.alphacoders.com/219/219081.gif\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a7e1ceb91be94b1da2ab8be97dfac999",
    "deepnote_cell_type": "markdown",
    "id": "CR3hzRxrrqDB"
   },
   "source": [
    "Motivado por incrementar su fortuna, Don Sergio le solicita entrenar un modelo que le permita segmentar a los pasajeros en grupos distintos, con el objetivo de optimizar las diversas campa√±as de marketing dise√±adas por su equipo. Para ello, le se pide realizar las siguientes tareas:\n",
    "\n",
    "1. Utilizar el modelo **Gaussian Mixture** y explore diferentes configuraciones de n√∫mero de cl√∫sters, espec√≠ficamente entre 3 y 8. Aseg√∫rese de integrar esta operaci√≥n dentro de un `pipeline`. [4 puntos]\n",
    "2. Explique cu√°l ser√≠a el criterio adecuado para seleccionar el n√∫mero √≥ptimo de cl√∫sters. **Justifique de forma estadistica y a traves de gr√°ficos.** [6 puntos]\n",
    "\n",
    "> **HINT:** Se recomienda investigar sobre los criterios AIC y BIC para esta tarea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jt_T_zTg0MXB"
   },
   "source": [
    "**Respuestas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "6d3d1bb3fda14321984466d9101a775a",
    "deepnote_cell_type": "code",
    "id": "5GeUb9J3rqDB"
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "# Escalador\n",
    "# Escalar\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df[selected_cols])\n",
    "\n",
    "aic_scores = []\n",
    "bic_scores = []\n",
    "ks = list(range(3, 9))\n",
    "\n",
    "for k in ks:\n",
    "    gmm = GaussianMixture(n_components=k, random_state=42)\n",
    "    gmm.fit(X_scaled)\n",
    "    aic_scores.append(gmm.aic(X_scaled))\n",
    "    bic_scores.append(gmm.bic(X_scaled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=ks, y=aic_scores, mode='lines+markers', name='AIC'))\n",
    "fig.add_trace(go.Scatter(x=ks, y=bic_scores, mode='lines+markers', name='BIC'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Comparaci√≥n de AIC y BIC para diferentes n√∫meros de cl√∫sters (GMM)',\n",
    "    xaxis_title='N√∫mero de cl√∫sters (k)',\n",
    "    yaxis_title='Score',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬øCu√°l es el criterio?\n",
    "\n",
    "AIC (Akaike Information Criterion) y BIC (Bayesian Information Criterion) penalizan la complejidad del modelo (m√°s cl√∫sters = m√°s par√°metros).\n",
    "\n",
    "Se busca el k donde AIC y BIC alcanzan su m√≠nimo o dejan de mejorar significativamente (\"codo\").\n",
    "\n",
    "Selecci√≥n √≥ptima:\n",
    "\n",
    "BIC es m√°s conservador (penaliza m√°s la complejidad).\n",
    "\n",
    "El n√∫mero √≥ptimo de cl√∫sters ser√° el que minimiza el BIC (o AIC). Si ambos coinciden en un mismo valor de k, mejor a√∫n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "dd342e336254418ba766b29dce16b267",
    "deepnote_cell_type": "markdown",
    "id": "P9CERnaerqDC"
   },
   "source": [
    "## 6. An√°lisis de resultados üìä [10 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "953b5ad01a704b50b899db7176d1b7b2",
    "deepnote_cell_type": "markdown",
    "id": "I1yNa111rqDC"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://www.icegif.com/wp-content/uploads/2021/12/icegif-1407.gif\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fd90e2f135404353ac0b5ab844936ca7",
    "deepnote_cell_type": "markdown",
    "id": "dg0Qx4RZrqDC"
   },
   "source": [
    "Una vez identificado el n√∫mero √≥ptimo de cl√∫sters, se le pide realizar lo siguiente:\n",
    "\n",
    "1. Utilizar la proyecci√≥n en dos dimensiones para visualizar cada cl√∫ster claramente. [2 puntos]\n",
    "\n",
    "2. ¬øEs posible distinguir claramente entre los cl√∫sters generados? [2 puntos]\n",
    "\n",
    "3. Proporcionar una descripci√≥n breve de cada cl√∫ster utilizando estad√≠sticas descriptivas b√°sicas, como la media y la desviaci√≥n est√°ndar, para resumir las caracter√≠sticas de las variables utilizadas en estos algoritmos. [2 puntos]\n",
    "\n",
    "4. Proceda a visualizar los cl√∫sters en tres dimensiones para una perspectiva m√°s detallada. [2 puntos]\n",
    "\n",
    "5. ¬øC√≥mo afecta esto a sus conclusiones anteriores? [2 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRN0zZip0IMB"
   },
   "source": [
    "**Respuestas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "9abf4dbc643e40cebe99fcb1ff3ff413",
    "deepnote_cell_type": "code",
    "id": "XmZrz15GrqDC"
   },
   "outputs": [],
   "source": [
    "optimal_k = ks[bic_scores.index(min(bic_scores))]  # basado en BIC\n",
    "\n",
    "gmm_final = GaussianMixture(n_components=optimal_k, random_state=42)\n",
    "gmm_final.fit(X_scaled)\n",
    "df['cluster'] = gmm_final.predict(X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df['cluster'] = gmm_final.predict(X_scaled)\n",
    "fig = px.scatter(\n",
    "    pca_df, x='PC1', y='PC2',\n",
    "    color='cluster',\n",
    "    title=f'Proyecci√≥n 2D de los cl√∫sters (k = {optimal_k})',\n",
    "    labels={'cluster': 'Cluster'},\n",
    "    opacity=0.7\n",
    ")\n",
    "fig.update_layout(template='plotly_white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S√≠, si los puntos se agrupan formando zonas claramente separadas, podemos decir que el modelo segment√≥ bien. En cambio, si hay solapamiento fuerte, eso podr√≠a indicar:\n",
    "\n",
    "* Variables no suficientemente discriminativas.\n",
    "\n",
    "* Cl√∫sters con formas no esf√©ricas o distribuciones no Gaussianas puras.\n",
    "\n",
    "* Una forma de reforzar esto ser√≠a calcular la Silhouette Score, aunque GMM no maximiza directamente esta m√©trica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir la variable cluster con los datos originales\n",
    "cluster_summary = df[selected_cols].copy()\n",
    "cluster_summary['cluster'] = df['cluster']\n",
    "\n",
    "# Calcular media y std por cl√∫ster\n",
    "summary_stats = cluster_summary.groupby('cluster').agg(['mean', 'std'])\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_3d = PCA(n_components=3)\n",
    "X_pca_3d = pca_3d.fit_transform(X_scaled)\n",
    "pca_3d_df = pd.DataFrame(X_pca_3d, columns=['PC1', 'PC2', 'PC3'])\n",
    "pca_3d_df['cluster'] = df.reset_index()['cluster'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(\n",
    "    pca_3d_df, x='PC1', y='PC2', z='PC3',\n",
    "    color='cluster',\n",
    "    title='Visualizaci√≥n 3D de cl√∫sters (GMM)',\n",
    "    opacity=0.7\n",
    ")\n",
    "fig.update_layout(template='plotly_white')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En 3D, se pueden notar separaciones m√°s claras o descubrir solapamientos no visibles en 2D. Si la separaci√≥n mejora en 3D, indica que al menos tres variables principales est√°n siendo √∫tiles para distinguir segmentos. Si el solapamiento persiste, puede ser necesario mejorar la selecci√≥n de variables o probar t√©cnicas m√°s complejas (como clustering jer√°rquico o DBSCAN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mucho √©xito!\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.pinimg.com/originals/55/3d/42/553d42bea9b10e0662a05aa8726fc7f4.gif\" width=300>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "7cb425aec99b4079954fd707109c42c3",
  "deepnote_persisted_session": {
   "createdAt": "2024-04-26T06:15:51.197Z"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
